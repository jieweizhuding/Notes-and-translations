感知机的思想是朴素的，作为硬分类的一种实现，其只能输出0和1,因此我们尝试找到一个超平面，使得
$$
\hat y_i=sign(\omega^T x_i)
$$
则可以表示为
$$
\begin{cases}
\hat y_iy_i>0,分类正确\\
\hat y_iy_i<0,分类错误
\end{cases}
$$
那么我们可以很轻松地找到loss function
$$
loss\ Function=\sum_{x_i,y_i \in D_{wrong}}(-y_isign(\omega^Tx_i))
$$
但是对于sign函数我们无法轻易求导，因此我们将其舍去，考察
$$
loss\ Function=L=\sum_{x_i,y_i \in D_{wrong}}(-y_i(\omega^Tx_i))\\
\frac{\partial L}{\partial\omega}=-x_iy_i
$$
该式虽然可以对$loss Function$进行表达，但使用SVD进行更新时，会将所有数据进行判断，计算十分复杂。因此提出了Novikoff定理，保证了使用小梯度下降的正确性。