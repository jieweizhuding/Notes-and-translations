## 经验误差与过拟合
<b>在训练过程中 </b>
分类错误的样本数占总样本数的比率为错误率
$$
E=\frac{a}{m}
$$
正确率为
$$
acc=1-E
$$
我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”(error),
学习器在训练集上的误差称为“训练误差”(training error)或“经验误差”(empirical error)
在新样本上的误差称为“泛化误差”(generalization error)

<b>
我们希望学习器的经验误差与泛化误差都较小，但这样的学习器表现一般都不好。
</b>

```
因为学习器存在过拟合与欠拟合的状态，当经验误差很小时，学习器会将训练样本的特征当作所有样本的特征，导致泛化误差增大。欠拟合是训练太少，无法总结出泛化的特征。

其中，欠拟合容易解决，可以增加样本量或训练次数。

而过拟合是无法解决的，因为机器学习面临的问题通常是NP 难甚至更难，
而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，
则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了 “P=NP” ；
因此，只 要相信“P != NP”，过拟合就不可避免。
```

<b>综上：经验误差与泛化误差都较小的学习器不是我们需要的，相比之下，我们更希望得到泛化误差较小的学习器，因此我们需要找到一个最好的模型，也就是“模型选择问题”。</b>

## 评估方法
要找到最好的模型，我们需要找到一个方法评估学习器。即如何量化泛化误差？
这里有两种思路：将部分样本用于训练，或将所有样本用于训练。
1. 将部分样本进行训练
因为我们要量化泛化误差，所以我们需要测试集，这部分测试集只能来自于样本集，故我们将样本集进行拆分。
因为只使用了部分样本集进行训练，必然会导致误差的增大。
    1. 留出法
    我们最简单的思路就是划分样本，采取分层抽样，即测试集中正例比例与训练集中正例比例相同，反例比例亦然。
    但是因为划分的方法不同，每次训练集不同，得到的学习器也不同，测试得到的泛化误差也不同，因此我们需要采取多种方式划分样本集，并对最终泛化误差结果取平均值。
    一般会选择2/3或4/5的数据作为训练集。
    2. 交叉验证法
    该方法是将样本集分成k份，其中1份作为测试集，剩下的作为训练集，可以重复k次这个过程，也就是能够得到k份学习器，每个学习器有都有对应的测试集，最后对其取平均值。这样的操作成为k折交叉验证。
    但是与留出法类似，不同的划分方法会导致不同的学习器，因此需要采用不同的划分方法重复p次，再取平均值，称为p次k折交叉验证。
    但如果样本集大小为m，采取m折交叉验证，则不同的划分对结果无影响，且每次训练只少一个数据，因此认为其结果较为准确。这个方法也称为留一法。然而这种方法的计算开销是难以忍受的，并且因为EFL原则，其并不一定优于其他方法。
2. 将所有样本进行训练
    1. 自助法
    给定m大小的样本集D，每次从中随机拷贝一个数据放入数据集D'中，直到D'的大小为m，则D'中的元素可能会有重复。D中的数据一直没有被选到的概率为:
    $$
    lim_{m\rightarrow +\infin}(1-\frac{1}{m})^m=\frac{1}{e}\approx 0.368
    $$
    即大约有36%的元素没有被选中，故我们使用D'作为训练集，D/D'作为测试集，故我们有m个数据用于训练，还有大约1/3的数据用于测试。
    自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集,这对集成学习等方法有很大的好处.
    然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.因此,在初始数据量足够时，留出法和交叉验证法更常用一些。

## 调参与最终模型
大多数大模型学习算法会有许多参数。因此，在进行模型评估与选择时不只需要选择合适的学习算法，也要对算法参数进行调节。
调参与算法选择类似之处在于：调参与算法选择都是对每个选择进行训练，得到模型，再进行评估，找到最好的选择，即参数。
不同之处在于：参数往往是连续的，而算法是离散的，因此我们会给定参数的取值区间与取值步长，类似二分法分割区间，从中选择离散的值。
因此，我们得到的参数往往不是最佳参数，而是对最佳参数的逼近值。所以，对参数的选择往往会最终模型性能有关键性影响。

此外，在使用m大小的数据集选择最终的模型后，我们需要用这个数据集对模型再训练一遍，保证其使用了所有个样本进行训练，此时这个模型才可以正式交付。

需要区分得到的最终模型后测试的数据与调优时使用的数据，我们可以将原始数据进行划分：
原始数据
├── 训练集（80%） → 用于模型训练和验证
│   ├── 子训练集（60%） → 更新模型参数
│   └── 验证集（20%） → 调参、选模型
└── 测试集（20%） → 最终性能评估（仅用一次！）

## 性能度量
刚刚介绍的是对学习器泛化能力评估的方法，如何具体度量模型的性能，仅仅靠泛化误差肯定是不够的，因此我们需要进一步找到其他的参数。
<b>
回归任务中最常用的是“均方误差”：
</b>

$$
E(f;D)=\frac{1}{m}\sum_{i=1}^{n}(f(x_i)-y_i)^2
$$
更一般的：
$$
E(f;D)=\int_{x \sim D}p(i)(f(x)-y)^2dx
$$
<b>这里我们主要讨论分类任务中常见的性能变量：</b>

1. 错误率与精度
错误率与精度是常用的两种性能度量，既适用于二分，也适用于多分类任务
$$
E(f;D)=\frac{1}{m} \sum_{i=1}^{m} \prod(f(x_i)\neq y_i)
$$
精度为：
$$
acc(f;D)=1-E(f;D)
$$
2. 查准率、查全率与F1
错误率与精度虽然常用，但有时不能满足需求，比如在搜索时，我们会更关心查找的准确率与全面程度
以二分为例：
我们可以将样例根据真实情况与预测情况进行分类
```
真实情况    预测结果
        正例        反例
正例    TP(真正例)  FN(假反例)
反例    FP(假正例)  TN(真反例)
```
查准率
$$
P=\frac{TP}{TP+FP}
$$
查全率
$$
R=\frac{TP}{TP+FN}
$$
一般我们认为P与R两者是矛盾的度量，不会同时很优秀
因此可以作出P-R曲线
![alt text](<../../图片/截图 2025-04-04 14-17-40.png>)
我们认为曲线包裹的面积越大，其越优秀，但部分曲线不易比较面积，故去找其平衡点，得到的横坐标越大认为其越优秀。称为BEP度量。
但BEP有时过于简化，故更常用F1度量
$$
\frac{1}{F_1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})
$$
但如追捕逃犯，更看重查全率，故有F1度量的一般形式。
$$
\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})
$$
3. ROC与AUC
模型会对正例与反例进行排序，正例的分数更高，反例的分数更低，一旦超过某个阈值，大于的判断为正例，小于为反例。
PR图只能反映特定的阈值下的情况，有些正例可能确实大于某些反例，但小于了阈值。因此PR图无法反映全局的排序情况，因此可以使用ROC。
TPR（真正率）：正确识别正样本的比例（越高越好）。
$$
TPR=\frac{TP}{TP+FN}
$$
FPR（假正率）：负样本被误判为正的比例（越低越好）。
$$
FPR=\frac{FP}{FP+TN}
$$
以这两者为横纵坐标作出ROC图，图像下的面积即为AUC。
![alt text](<../../图片/截图 2025-04-04 15-00-23.png>)
AUC的意义为：
0.5->随机排序
1->完美排序
我们认为AOC越大，则模型越优秀。
因为我们通过改变阈值得到了ROC，所以它衡量的是全局的排序情况，不受样本排序的影响。

```
现实任务中通常是利用有限个测试样例来绘制 ROC图 ,
此时仅能获得有限个(真正例率,假正例率)坐标对,
无法产生图2.4(a) 中的光滑 ROC 曲线，
只能绘制出如图 2.4(b)所示的近似ROC曲线.
绘图过程很简单：给定m+个正例和m-个反例，
根据学习器预测结果对样例进行排序，然后把分类阈值设为最大,
即把所有样例均预测为反例，此时真正例率和假正例率均为0, 在坐标(0,0)处标记一个点.
然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例.
设前一个标记点坐标为(x,y),
当前若为真正例，则对应标记点的坐标为(x，y+1/(m+));
当前若为假正例,则对应标记点的坐标为(x+1/(m-),y)，然后用线段连接相邻点即得.
```

4. 代价敏感错误率与代价曲线
有些问题错误后的损失会不同，比如医生诊断病人，FP会导致病人错过最佳治疗时机，而FN只会令病人检查的流程变复杂些。
为了衡量不同类型错误带来的损失，可为错误赋予“非均等代价”。
```
真实情况    预测结果
        正例        反例
正例      0        cost01
反例    cost10       0
```
回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价.在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”(total cost)
代价敏感错误率为：
$$
E(f;D;cost)=\frac{1}{m}()
$$